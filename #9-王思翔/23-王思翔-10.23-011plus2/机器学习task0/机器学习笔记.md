# 一，神经网络和pytorch

## 1.神经网络

==定义：==网上摘得的定义是：神经网络又称人工神经网络 (ANN) 或模拟神经网络 (SNN)，是机器学习的子集，同时也是深度学习算法的核心。  其名称和结构均受到人脑的启发，可模仿生物神经元相互传递信号的方式。

人工神经网络 (ANN) 由节点层组成，包含一个输入层、一个或多个隐藏层和一个输出层。 每个节点也称为一个人工神经元，它们连接到另一个节点，具有相关的权重和阈值。 如果任何单个节点的输出高于指定的阈值，那么会激活该节点，并将数据发送到网络的下一层。 否则，不会将数据传递到网络的下一层。

神经网络依靠训练数据来学习，并随时间推移提高自身准确性。 而一旦这些学习算法经过了调优，提高了准确性，它们就会成为计算机科学和人工智能领域的强大工具，使我们能够快速对数据进行分类和聚类。  与由人类专家进行的人工识别相比，语音识别或图像识别任务可能只需要几分钟而不是数小时。 Google 的搜索算法就是最著名的神经网络之一。

**俺自己寻思了一下，简单概括为： ** **一种以人工神经元为基本单位的模型，并可以依靠数据的投喂来提升能力，提高效率**

==知识点：==（1）人工神经元：由生物启发做成的数据是否传输的判断器*（即数据是否到达阈值，然后决定是否传输数据）*

​               （2）输入层，隐藏层与输出层：输入层即起点（input）,，输入数据，隐藏层（中间层）为解决问题过程中所需要的许多节点，但其所产生的数据并不会直接输出出去（不体现在输出上），输出层为终点（output），输出数据（排版很丑还请见谅呜呜呜）

==*图中线条即为进行了一次线性操作*==

![xuexi1.png](https://s2.loli.net/2023/10/23/LzJkXqQaB4jH2t3.png)

*(本人已经上传至图床，若无法显示请看xuexi1这个图片)*



​              （3）权重：斜率，ax+b中的a，权重可改进输出，大权重强化数据，小权重弱化数据

​                        权重更新：对a进行一次公式计算，然后更新a的值

## 2.pytorch

==定义：==PyTorch 是一种用于构建**深度学习模型的功能完备框架，是一种通常用于图像识别和语言处理等应用程序的机器学习。**

PyTorch 是一种==开源深度学习框架==，以出色的灵活性和易用性著称。这在一定程度上是因为与机器学习开发者和数据科学家所青睐的热门 Python 高级编程语言兼容。

***

# 二，机器学习

## 1.应用方向：

工厂应用，医学，农业，电子商务等等

## 2.一些基本概念

==1.定义：==使计算机无需明确编程即可学习的研究领域。从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法

***

监督学习：指学习x到y或输入到输出映射的算法，关键特征是你给予学习算法示例（必须包括正确的答案），从这些输入，输出或x和y的对应中学习后，它们变得可以接受一个全新的输入x，并产生相应的输出y

人话就是吃数据然后让其输入一个全新数据时可以让它产生预测的结果（基本上吃的正确数据越多越贴近正确答案）

**eg.各种股票预测算法**

***

无监督学习：它使用机器学习算法来分析未标记的数据集并进行聚类。 这些算法无需人工干预，即可发现隐藏的模式或数据分组。

发现一堆数据的分布情况，模式，结构等，这种方法能够发现信息的相似性和差异性，因而是探索性数据分析、交叉销售策略、客户细分和图像识别的理想解决方案。无需为数据贴上标签

==你无法获知无监督学习下的模型会发展成什么确切的样子==

**eg.有很多违法行为都需要"洗钱"，这些洗钱行为跟普通用户的行为是不一样的，如果通过人为去分析是一件成本很高很复杂的事情，我们可以通过这些行为的特征对用户进行分类，就更容易找到那些行为异常的用户，然后再深入分析他们的行为到底哪里不一样，是否属于违法洗钱的范畴。**

**eg.广告对目标人群的投放**

**通过无监督学习，我们可以快速把行为进行分类，虽然我们不知道这些分类意味着什么，但是通过这种分类，可以快速排出正常的用户，更有针对性的对异常行为进行深入分析。**

***

分类器：分类是一项依赖于机器学习算法（Machine Learning Algorithm）的自然语言处理任务，在有监督学习中，最主要的两种学习任务是 回归（regression） 和 分类（classification），而其中 线性回归 和 线性分类 最为常见。线性回归是预测某一个具体的值，而线性分类是数据所属类别进行预测。一般来说，几乎 80% 机器学习任务可以看作是某种分类问题。分类，即给定一个输入的集合，分类器致力于预测每一个类别的概率。类别标记（也被称为 应变量或依赖变量）是一个离散的值，表示某个类别。

==分类定义:==分类是识别、理解，并将想法、对象分到预设类别或“子群”的过程。机器学习程序使用预先分类的训练数据集，通过各种算法对未来的数据集进行分类。

**eg.给一堆猫猫，狗狗图片，机器自行将其分类并识别新输入的图片是猫还是狗**

***

预测器：对于一个输入数据所可能产生的结果进行预测，就不说那些弯弯绕绕了，

==与监督学习密切相关==

**eg.输入父母身高，推测孩子身高**

***

***

读热码：独热编码即 One-Hot 编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。. 虽然使用较多的触发器，但由于状态译码简单，可减少组合逻辑且速度较快， 这种编码方式还易于修改，增加状态或改变状态转换条件都可以在不影响状态机的其它部分的情况下很方便地实现。

**eg.**

**性别特征：["男"，"女"]（这里N=2）
男 => 10
女 => 01**

**地区特征：["北京"，"上海，"深圳"]（这里N=3）：
北京 => 100
上海 => 010
深圳 => 001**

**工作特征：["演员"，"厨师"，"公务员"，"工程师"，"律师"]（这里N=5）：
演员 => 10000
厨师 => 01000
公务员 => 00100
工程师 => 00010
律师 => 00001**

**所以，样本的特征是["女","北京","工程师"]的时候，独热编码（One-Hot Encoding）的结果为：**

**[0，1，1，0，0，0，0，0，1，0]**

***

向量化：向量化计算(vectorization)，也叫vectorized operation，也叫array programming，说的是一个事情：将多次for循环计算变成一次计算。



![xuexi3.jpg](https://s2.loli.net/2023/10/23/1nDiGkQuK6SA83l.jpg)

*(本人已经上传至图床，若无法显示请看xuexi3这个图片)*



***

神经元，输入/隐藏/输出层都在上文进行过阐述，权重/权重更新也在上文阐述 [点我跳转](#1.神经网络)

***

# 三，上为老版本笔记，现在开始是新笔记（生活不易，思翔叹气）

## 1.机器学习与深度学习区别与定义

**（1）机器学习：**使计算机无需明确编程即可学习的研究领域。从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法

**（2）深度学习：**深度学习是一种机器学习的==特殊分支==，它通过多层次的神经网络模型来==模拟和学习人脑的神经网络结构==，以实现对数据的高级抽象和表征学习。深度学习的核心思想是通过==多层次的神经元计算==，逐层提取数据的特征表示，并通过反向传播算法来优化网络参数，从而实现对数据的自动分类、识别和预测等任务。

*简单来说，深度学习是机器学习的特殊分支*

***

## 2.监督学习与无监督学习

在上方 [点我跳转](#2.一些基本概念)

***

## 3.**偏导数**是什么？**链式法则**是什么？**梯度**又是什么？**矩阵乘法**怎么操作？

**(1)偏导数:** 偏导数**反映的是函数沿 坐标轴 正方向 的变化率**。

![xuexi2.jpg](https://s2.loli.net/2023/10/23/gUy5cztOf1IRQEd.jpg)

*(本人已经上传至图床，若无法显示请看xuexi2这个图片)*

**(2)链式法则：** 复合函数的求导公式也叫**链式法则**，假设有两个函数y = f(u)和u = g(x)，那么复合函数y = f(g(x))。根据链式法则，我们可以得到：f(g(x))=df(u) * dg(x)

**(3)梯度：**在数学和机器学习中，梯度是一个向量，它表示函数在某一点上的==变化率和方向==。梯度可以理解为函数在某一点上的导数（即斜率）的==推广==。

对于一个多变量函数 f(x1, x2, ..., xn)，它的梯度由各个偏导数组成，表示为∇f(x1, x2, ..., xn)。其中，∇表示梯度运算符，它是一个向量算子。

梯度向量的每个分量都表示函数在对应变量方向上的变化率。例如，对于二维函数 f(x, y)，其梯度向量为∇f(x, y) = (∂f/∂x, ∂f/∂y)，其中 (∂f/∂x, ∂f/∂y) 分别表示函数在 x 方向和 y 方向上的**变化率。**

梯度的方向是函数在某一点上变化最快的方向，梯度的大小表示了变化率的大小。通过梯度的计算，可以找到函数的最大值或最小值点，从而在优化问题中进行参数的调整和优化。

在机器学习中，梯度的应用非常广泛，特别是在==梯度下降==算法中。梯度下降算法通过迭代地沿着梯度的反方向更新参数，逐步寻找函数的最小值点。通过梯度下降算法，可以有效地优化损失函数，并得到模型的最优参数。

==即有方向的斜率变化量==

**（4）矩阵乘法：**形如A*B=C的乘法，c~ij~即为A的i行乘上B的j列

**（5）损失向量：**一言以蔽之，损失函数（loss function）就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数

**（6）梯度下降：**它的主要目的是==通过迭代找到目标函数的最小值，或者收敛到最小值。==

梯度下降法的基本思想可以类比为一个下山的过程。
假设这样一个场景：一个人被困在山上，需要从山上下来(找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低；因此，下山的路径就无法确定，必须利用自己周围的信息一步一步地找到下山的路。这个时候，便可利用梯度下降算法来帮助自己下山。怎么做呢，首先以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着下降方向走一步，然后又继续以当前位置为基准，再找最陡峭的地方，再走直到最后到达最低处；同理上山也是如此，只是这时候就变成梯度上升算法了  [参考文章](https://blog.csdn.net/qq_41800366/article/details/86583789)

![xuexi4.png](https://s2.loli.net/2023/10/23/WvsYCp1qmwkySbo.png)

*(本人已经上传至图床，若无法显示请看xuexi4这个图片)*

==**梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的下降最快的方向**==

**（7）反向传播：**反向传播算法是目前用来训练人工神经网络的最常用且最有效的算法。输入结果与输出结果有误差，则计算估计值与实际值之间的误差，并将该误差从输出层向隐藏层反向传播，直至传播到输入层。【输出层–隐藏层–输入层】

eg.个人在玩你画我猜的游戏，然后第一个人给第二个人描述，再将信息传递给第三个人，由第三个人说出画的到底是啥。第三个人得知自己说的和真实答案之间的误差后，发现他们在传递时的问题差在哪里，向前面一个人说下次描述的时候怎样可以更加准确的传递信息。就这样一直向前一个人告知。

**（8）样本：**数据集中每条记录是关于一个事件或对象的描述，称为"样本" ，简单来说，一行为一个样本

​          **特征（属性）：**反映事件或对象在某方面的表现或性质的事项，例如"色泽"，"根蒂"等

​          **激活函数：**y=u(z),u即为激活函数



**（9）线性回归：**线性回归可以说是用法非常简单、用处非常广泛、含义也非常容易理解的一类算法，作为机器学习的入门算法非常合适。我们上中学的时候，都学过二元一次方程，我们将y作为因变量，x作为自变量，得到方程 的时候，画在坐标图内是一条直线（这就是“线性”的含义）。

![xuexi5.png](https://s2.loli.net/2023/10/23/6U8BH7ZA23pWDMV.png)

*(本人已经上传至图床，若无法显示请看xuexi5这个图片)*

当我们只用一个x来预测y，就是一元线性回归，也就是在找一个直线来拟合数据。比如，我有一组数据画出来的散点图，横坐标代表广告投入金额，纵坐标代表销售量，线性回归就是要找一条直线，并且让这条直线尽可能地拟合图中的数据点。

**数学理论的世界是精确的**，但现实世界中的数据就像这个散点图，我们只能尽可能地在杂乱中寻找规律。用数学的模型去拟合现实的数据，这就是统计。统计不像数学那么精确，统计的世界不是非黑即白的，它有“灰色地带”，但是统计会将理论与实际间的差别表示出来，也就是“误差”。
因此，统计世界中的公式会有一个小尾巴μ ，用来代表误差

​      **逻辑回归：**逻辑回归也称作[logistic回归](https://so.csdn.net/so/search?q=logistic回归&spm=1001.2101.3001.7020)分析，是一种广义的线性回归分析模型，属于==机器学习中的监督学习==。

逻辑回归是一种分类算法，但该分类的标准，是通过h(x)输入后，使用sigmoid函数进行转换，同时根据阈值，就能够针对不同的h(x)值，输出0-1之间的数。我们将这个0-1之间的输出，认为是概率。假设阈值是0.5，那么，大于0.5的我们认为是1，否则认为是0。逻辑回归适用于二分类问题。

==区别：==

线性回归主要功能是**拟合数据**。
逻辑回归主要功能是**区分数据**，找到决策边界。

![xuexi6.png](https://s2.loli.net/2023/10/23/67dmO9VjyKzfXTL.png)

*(本人已经上传至图床，若无法显示请看xuexi6这个图片)*

**数据集：**数据记录的集合称为一个数据集

**训练集（Training Set）：**帮助我们训练模型，即通过训练集的数据让我们确定拟合曲线的参数。
**验证集（Validation Set）：**用来做模型选择（model selection），即做模型的==最终优化及确定的==，用来辅助我们的模型的构建，可选
**测试集（Test Set）：** 为了测试已经训练好的模型的精确度。因为在训练模型的时候，参数全是根据现有训练集里的数据进行修正、拟合，有可能会出现过拟合的情况，即这个参数仅对训练集里的数据拟合比较准确，如果出现一个新数据需要利用模型预测结果，准确率可能就会很差。
所以测试集的作用是为了对学习器的泛化误差进行评估，即进行实验测试以判别学习器对新样本的判别能力，同时以测试集的的测试误差”作为泛化误差的近似。因此在分配训练集和测试集的时候，**如果测试集的数据越小，对模型的泛化误差的估计将会越不准确**。所以需要在划分数据集的时候进行权衡。

**softmax函数：**Softmax是一种激活函数，它可以将一个数值向量归一化为一个概率分布向量，且各个概率之和为1。Softmax可以用来作为神经网络的最后一层，用于多分类问题的输出。

